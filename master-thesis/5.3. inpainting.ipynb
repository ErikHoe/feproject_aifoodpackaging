{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d1c8dfb1-813a-4952-8cbf-c9522938ee7f",
   "metadata": {},
   "source": [
    "# 5.3. Inpainting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f93e45fa-561a-4b84-ab0a-714fb9613675",
   "metadata": {},
   "source": [
    "## Evaluation\n",
    "\n",
    "Inpainting was tested to determine the extent to which **images** and **texts** can be created on food packaging. \n",
    "\n",
    "For this purpose, **pure inpainting** and **inpainting in combination with dreambooth** were used, resulting in a total of **four evaluations** in each case.\n",
    "\n",
    "For each training, 50 output images were generated, which were rated as “achieved” and “not achieved” in the following categories:\n",
    "\n",
    "1. **brand coherence**\n",
    "2. **target design**\n",
    "3. **visual aesthetics**\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "**Find the evaluated image-grids under:**\n",
    "\n",
    "[Anhang 04_Inpainting](anhang/anhang%2004_inpainting/)\n",
    "\n",
    "[Anhang 06_Inpainting Nesquik](anhang/anhang%2006_nesquik_inpainting/)\n",
    "\n",
    "**And the Inpainting masks under:**\n",
    "\n",
    "[ControlNet Mask](assets/)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24249c83-77dd-46fe-871e-9f22f098cfba",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a850791-0f08-4771-8be4-a9ea10dec501",
   "metadata": {},
   "outputs": [],
   "source": [
    "%env HF_HOME=/cluster/user/ehoemmen/.cache\n",
    "%env HF_DATASETS_CACHE=/cluster/user/ehoemmen/.cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc04d507-c3c4-44a8-8474-bc3cf0ed36cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install diffusers invisible_watermark transformers accelerate safetensors matplotlib -q --upgrade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cc8a37f-abbb-4fd3-94d2-061579d13850",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Image Grid\n",
    "def image_grid(imgs, rows, cols):\n",
    "    assert len(imgs) == rows*cols\n",
    "\n",
    "    w, h = imgs[0].size\n",
    "    grid = Image.new('RGB', size=(cols*w, rows*h))\n",
    "    grid_w, grid_h = grid.size\n",
    "    \n",
    "    for i, img in enumerate(imgs):\n",
    "        grid.paste(img, box=(i%cols*w, i//cols*h))\n",
    "    return grid"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb1c9f74-5270-4fc8-b272-dc3f54b21233",
   "metadata": {},
   "source": [
    "## Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91a89c20-4887-44a9-9c62-0c231acbe7ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from diffusers import StableDiffusionXLInpaintPipeline\n",
    "from diffusers.utils import load_image\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "pipe = StableDiffusionXLInpaintPipeline.from_pretrained(\n",
    "    \"stabilityai/stable-diffusion-xl-base-1.0\",\n",
    "    torch_dtype=torch.float16,\n",
    "    variant=\"fp16\",\n",
    "    use_safetensors=True,\n",
    "    cache_dir=\"/cluster/user/ehoemmen/.cache\"\n",
    ")\n",
    "pipe.enable_sequential_cpu_offload()\n",
    "\n",
    "# load fine-tuned LoRa-weights\n",
    "pipe.load_lora_weights(\"erikhsos/cbbier_06-15-images_LoRA_lr1-4_2000\")\n",
    "\n",
    "# unload LoRa-weights\n",
    "#pipe.unload_lora_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c0b00ff-9a4f-4cc7-bc6b-17fa33117364",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import os\n",
    "\n",
    "img_url = load_image(\n",
    "# '/cluster/user/ehoemmen/development/tests_sonstiges/05_Masterarbeit/03_inpainting/campusbier_input.png'\n",
    ")\n",
    "\n",
    "mask_url = load_image(\n",
    "'/cluster/user/ehoemmen/development/tests_sonstiges/05_Masterarbeit/03_inpainting/inpainting_mask_schmied.png'   #enter path\n",
    ")\n",
    "init_image = load_image(img_url).convert(\"RGB\")\n",
    "mask_image = load_image(mask_url).convert(\"RGB\")\n",
    "\n",
    "num_images = 6\n",
    "\n",
    "# select manual seed, if necessary\n",
    "#generator = torch.manual_seed(493)\n",
    "\n",
    "prompt = [\"sliced lemon drawing with a leaf, beer label design\"] * num_images\n",
    "neg_prompt = \"drawing of a building\"\n",
    "\n",
    "image = pipe(\n",
    "    prompt=prompt,\n",
    "    negative_prompt=neg_prompt, \n",
    "    image=init_image, mask_image=mask_image,\n",
    "    #generator=generator, \n",
    "    num_inference_steps=25, \n",
    "    strength=0.80,\n",
    "    guidance_scale=5.0\n",
    ").images\n",
    "\n",
    "grid = image_grid(image, rows=1, cols=num_images)\n",
    "\n",
    "grid"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f3fd379-a038-4d02-80b9-08e76379eacb",
   "metadata": {},
   "source": [
    "## Results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc84aca3-226c-407d-870f-acaf55eebd10",
   "metadata": {},
   "source": [
    "**Best** inpainting results were archieved when using **inpainting x dreambooth** for image generation. In combination with the fine-tuned LoRa-weights the results match the original packaging design best.\n",
    "It's possible to generate images with **inpainting only** but the relevant designs decrease a lot.\n",
    "\n",
    "It's **not** possible to generate **text** on food packagings."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
