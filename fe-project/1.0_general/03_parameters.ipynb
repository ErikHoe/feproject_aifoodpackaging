{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f2df8e1f-3e75-40e6-b6ac-2cbd5bba363f",
   "metadata": {},
   "source": [
    "# 01. General\n",
    "\n",
    "## 03. SDXL Parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35afe5c7-b2dd-4b19-9523-95659ceab897",
   "metadata": {},
   "source": [
    "https://huggingface.co/docs/diffusers/api/pipelines/stable_diffusion/stable_diffusion_xl\n",
    "\n",
    "* **prompt** (str or List[str], optional) — The prompt or prompts to guide the image generation. If not defined, one has to pass prompt_embeds. instead.\n",
    "  \n",
    "* **prompt_2** (str or List[str], optional) — The prompt or prompts to be sent to the tokenizer_2 and text_encoder_2. If not defined, prompt is used in both text-encoders\n",
    "  \n",
    "* **height** (int, optional, defaults to self.unet.config.sample_size * self.vae_scale_factor) — The height in pixels of the generated image. This is set to ***1024 by default*** for the best results. Anything below 512 pixels won’t work well for stabilityai/stable-diffusion-xl-base-1.0 and checkpoints that are not specifically fine-tuned on low resolutions.\n",
    "* **width** (int, optional, defaults to self.unet.config.sample_size * self.vae_scale_factor) — The width in pixels of the generated image. This is set to ***1024 by default*** for the best results. Anything below 512 pixels won’t work well for stabilityai/stable-diffusion-xl-base-1.0 and checkpoints that are not specifically fine-tuned on low resolutions.\n",
    "* **num_inference_steps** (int, optional, ***defaults to 50***) — The number of ***denoising steps***. More denoising steps usually lead to a higher quality image at the expense of slower inference.\n",
    "* **denoising_end** (float, optional) — When specified, determines the fraction (***between 0.0 and 1.0***) of the total denoising process to be completed before it is intentionally prematurely terminated. As a result, the returned sample will still retain a substantial amount of noise as determined by the discrete timesteps selected by the scheduler. The denoising_end parameter should ideally be utilized when this pipeline forms a part of a “Mixture of Denoisers” multi-pipeline setup, as elaborated in Refining the Image Output\n",
    "* **guidance_scale** (float, optional, ***defaults to 7.5***) — Guidance scale as defined in ***Classifier-Free Diffusion Guidance (cfg)***. guidance_scale is defined as w of equation 2. of Imagen Paper. Guidance scale is enabled by setting guidance_scale > 1. *Higher guidance scale encourages to generate images that are closely linked to the text prompt, usually at the expense of lower image quality.*\n",
    "* **negative_prompt** (str or List[str], optional) — The prompt or prompts not to guide the image generation. If not defined, one has to pass negative_prompt_embeds instead. Ignored when not using guidance (i.e., ignored if guidance_scale is less than 1).\n",
    "* **negative_prompt_2** (str or List[str], optional) — The prompt or prompts not to guide the image generation to be sent to tokenizer_2 and text_encoder_2. If not defined, negative_prompt is used in both text-encoders\n",
    "* **num_images_per_prompt** (int, optional, ***defaults to 1***) — The number of images to generate per prompt.\n",
    "* **eta** (float, optional, ***defaults to 0.0***) — Corresponds to parameter eta (η) in the DDIM paper: https://arxiv.org/abs/2010.02502. Only applies to schedulers.DDIMScheduler, will be ignored for others.\n",
    "* **generator** (torch.Generator or List[torch.Generator], optional) — One or a list of torch generator(s) to ***make generation deterministic***.\n",
    "    > ***<ins>set manuel seed:</ins>*** generator = torch.Generator().manual_seed(33)\n",
    "    \n",
    "    \n",
    "* **latents** (torch.FloatTensor, optional) — Pre-generated noisy latents, sampled from a Gaussian distribution, to be used as inputs for image generation. Can be used to tweak the same generation with different prompts. *If not provided, a latents tensor will ge generated by sampling using the supplied random generator.*\n",
    "* **prompt_embeds** (torch.FloatTensor, optional) — Pre-generated text embeddings. Can be used to easily tweak text inputs, e.g. ***prompt weighting***. If not provided, text embeddings will be generated from prompt input argument.\n",
    "* **negative_prompt_embeds** (torch.FloatTensor, optional) — Pre-generated negative text embeddings. Can be used to easily tweak text inputs, e.g. ***prompt weighting***. If not provided, negative_prompt_embeds will be generated from negative_prompt input argument.\n",
    "* **pooled_prompt_embeds** (torch.FloatTensor, optional) — Pre-generated pooled text embeddings. Can be used to easily tweak text inputs, e.g. ***prompt weighting***. If not provided, pooled text embeddings will be generated from prompt input argument.\n",
    "* **negative_pooled_prompt_embeds** (torch.FloatTensor, optional) — Pre-generated negative pooled text embeddings. Can be used to easily tweak text inputs, e.g. ***prompt weighting***. If not provided, pooled negative_prompt_embeds will be generated from negative_prompt input argument.\n",
    "* **output_type** (str, optional, ***defaults to \"pil\"***) — The output format of the generate image. Choose between PIL: PIL.Image.Image or np.array.\n",
    "* **return_dict** (bool, optional, ***defaults to True***) — Whether or not to return a StableDiffusionXLPipelineOutput instead of a plain tuple.\n",
    "* **callback** (Callable, optional) — A function that will be called every callback_steps steps during inference. The function will be called with the following arguments: callback(step: int, timestep: int, latents: torch.FloatTensor).\n",
    "* **callback_steps** (int, optional, ***defaults to 1***) — The frequency at which the callback function will be called. If not specified, the callback will be called at every step.\n",
    "* **cross_attention_kwargs** (dict, optional) — A kwargs dictionary that if specified is passed along to the AttentionProcessor as defined under self.processor in diffusers.models.attention_processor.\n",
    "* **guidance_rescale** (float, optional, ***defaults to 0.7***) — Guidance rescale factor proposed by Common Diffusion Noise Schedules and Sample Steps are Flawed guidance_scale is defined as φ in equation 16. of Common Diffusion Noise Schedules and Sample Steps are Flawed. Guidance rescale factor should fix overexposure when using zero terminal SNR.\n",
    "* **original_size** (Tuple[int], optional, ***defaults to (1024, 1024)***) — If original_size is not the same as target_size the image will appear to be down- or upsampled. original_size defaults to (width, height) if not specified. Part of SDXL’s micro-conditioning as explained in section 2.2 of https://huggingface.co/papers/2307.01952.\n",
    "* **crops_coords_top_left** (Tuple[int], optional, ***defaults to (0, 0)***) — crops_coords_top_left can be used to generate an image that appears to be “cropped” from the position crops_coords_top_left downwards. Favorable, well-centered images are usually achieved by setting crops_coords_top_left to (0, 0). Part of SDXL’s micro-conditioning as explained in section 2.2 of https://huggingface.co/papers/2307.01952.\n",
    "* **target_size** (Tuple[int], optional, ***defaults to (1024, 1024)***) — For most cases, target_size should be set to the desired height and width of the generated image. If not specified it will default to (width, height). Part of SDXL’s micro-conditioning as explained in section 2.2 of https://huggingface.co/papers/2307.01952.\n",
    "* **negative_original_size** (Tuple[int], optional, ***defaults to (1024, 1024)***) — To negatively condition the generation process based on a specific image resolution. Part of SDXL’s micro-conditioning as explained in section 2.2 of https://huggingface.co/papers/2307.01952. For more information, refer to this issue thread: https://github.com/huggingface/diffusers/issues/4208.\n",
    "* **negative_crops_coords_top_left** (Tuple[int], optional, ***defaults to (0, 0)***) — To negatively condition the generation process based on a specific crop coordinates. Part of SDXL’s micro-conditioning as explained in section 2.2 of https://huggingface.co/papers/2307.01952. For more information, refer to this issue thread: https://github.com/huggingface/diffusers/issues/4208.\n",
    "* **negative_target_size** (Tuple[int], optional, ***defaults to (1024, 1024)***) — To negatively condition the generation process based on a target image resolution. It should be as same as the target_size for most cases. Part of SDXL’s micro-conditioning as explained in section 2.2 of https://huggingface.co/papers/2307.01952. For more information, refer to this issue thread: https://github.com/huggingface/diffusers/issues/4208.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
