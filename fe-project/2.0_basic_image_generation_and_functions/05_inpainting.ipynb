{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "107d37bd-c03f-429c-9d11-5cbeb2a6142e",
   "metadata": {},
   "source": [
    "# 02. Basic Image Generation + Functions\n",
    "\n",
    "## 05. Inpainting\n",
    "\n",
    "### Content:\n",
    "1. [Initialzation + Tiger Example](#init)\n",
    "2. [Example - Kelloggs](#kelloggs)\n",
    "3. [Example - RUF Backmischung](#ruf)\n",
    "4. [Key-Findings](#keyfind1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79143acf-54d4-47ad-8f51-5e14f8b36f0b",
   "metadata": {},
   "source": [
    "## Description + Links\n",
    "\n",
    "SD-XL Inpainting 0.1 is a latent text-to-image diffusion model capable of generating photo-realistic images given any text input, with the extra capability of inpainting the pictures by using a mask.\n",
    "\n",
    "The SD-XL Inpainting 0.1 was initialized with the stable-diffusion-xl-base-1.0 weights. The model is trained for 40k steps at resolution 1024x1024 and 5% dropping of the text-conditioning to improve classifier-free guidance sampling. For inpainting, the UNet has 5 additional input channels (4 for the encoded masked-image and 1 for the mask itself) whose weights were zero-initialized after restoring the non-inpainting checkpoint. During training, we generate synthetic masks and, in 25% mask everything.\n",
    "\n",
    "**Pipeline Parameters:**\n",
    "* **Strength** is a measure of how much noise is added to the base image, which influences how similar the output is to the base image.\n",
    "    * ***High strength*** = more noise is added and the denoising process takes longer, but you'll get higher quality images that are more different from the base image\n",
    "    * ***low strength*** = less noise is added and the denoising process is faster, but the image quality may not be as great and the generated images resembles the base image more\n",
    " \n",
    "* **Guidance Scale:**\n",
    "    * ***high guidance scale*** = the prompt and the generated image are closely aligned, the output is a stricter interpretation of the prompt\n",
    "    * ***low guidance scale*** = the prompt and generated image are more loosely aligned, so the output may be more varied from the prompt\n",
    "\n",
    "---\n",
    "\n",
    "https://huggingface.co/docs/diffusers/api/pipelines/stable_diffusion/stable_diffusion_xl\n",
    "\n",
    "https://huggingface.co/diffusers/stable-diffusion-xl-1.0-inpainting-0.1\n",
    "\n",
    "https://huggingface.co/docs/diffusers/using-diffusers/inpaint"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f1360b5-7132-475d-ab47-2a45dd22ba10",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4a53a27-32f4-443f-bed2-d925418ed23f",
   "metadata": {},
   "outputs": [],
   "source": [
    "%env HF_HOME=/cluster/user/ehoemmen/.cache\n",
    "%env HF_DATASETS_CACHE=/cluster/user/ehoemmen/.cache\n",
    "%env TRANSFORMERS_CACHE=/cluster/user/ehoemmen/.cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de2a1a36-2905-4391-ab64-257dfac97a62",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install -U diffusers invisible_watermark transformers accelerate safetensors matplotlib"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ef07deb-e6c8-421a-b676-4f5425f68683",
   "metadata": {},
   "source": [
    "<a id=\"init\"></a>\n",
    "\n",
    "## 1. Initialization  + Tiger Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db7a7af0-4aee-493d-96ce-c41dc523e710",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from diffusers import StableDiffusionXLInpaintPipeline\n",
    "from diffusers.utils import load_image\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "pipe = StableDiffusionXLInpaintPipeline.from_pretrained(\n",
    "    \"stabilityai/stable-diffusion-xl-base-1.0\",\n",
    "    torch_dtype=torch.float16,\n",
    "    variant=\"fp16\",\n",
    "    use_safetensors=True,\n",
    "    cache_dir=\"/cluster/user/ehoemmen/.cache\"\n",
    ")\n",
    "pipe.enable_sequential_cpu_offload()\n",
    "\n",
    "# image grid\n",
    "from PIL import Image\n",
    "\n",
    "#Image Grid\n",
    "def image_grid(imgs, rows, cols):\n",
    "    assert len(imgs) == rows*cols\n",
    "\n",
    "    w, h = imgs[0].size\n",
    "    grid = Image.new('RGB', size=(cols*w, rows*h))\n",
    "    grid_w, grid_h = grid.size\n",
    "    \n",
    "    for i, img in enumerate(imgs):\n",
    "        grid.paste(img, box=(i%cols*w, i//cols*h))\n",
    "    return grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25e3fc5c-ac40-422a-8b25-0f0cf7b83b4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_url = \"https://raw.githubusercontent.com/CompVis/latent-diffusion/main/data/inpainting_examples/overture-creations-5sI6fQgYIuo.png\"\n",
    "mask_url = \"https://raw.githubusercontent.com/CompVis/latent-diffusion/main/data/inpainting_examples/overture-creations-5sI6fQgYIuo_mask.png\"\n",
    "\n",
    "init_image = load_image(img_url).convert(\"RGB\")\n",
    "mask_image = load_image(mask_url).convert(\"RGB\")\n",
    "\n",
    "prompt = \"A majestic tiger sitting on a bench\"\n",
    "image = pipe(\n",
    "    prompt=prompt, \n",
    "    image=init_image, \n",
    "    mask_image=mask_image, \n",
    "    num_inference_steps=50, \n",
    "    strength=0.80\n",
    ").images[0]\n",
    "\n",
    "\n",
    "# Bilder mit matplotlib darstellen\n",
    "fig, axes = plt.subplots(1, 3, figsize=(20, 8))\n",
    "\n",
    "# Ursprüngliches Bild anzeigen\n",
    "axes[0].imshow(init_image)\n",
    "axes[0].axis('off')\n",
    "axes[0].set_title('Original Image')\n",
    "\n",
    "# Inpaint Mask anzeigen\n",
    "axes[1].imshow(mask_image)\n",
    "axes[1].axis('off')\n",
    "axes[1].set_title('Inpaint Image')\n",
    "\n",
    "# Generiertes Bild anzeigen\n",
    "axes[2].imshow(image)\n",
    "axes[2].axis('off')\n",
    "axes[2].set_title(prompt)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45f2d7d2-239d-49f1-80e2-8864e6e956b0",
   "metadata": {},
   "source": [
    "<a id=\"kelloggs\"></a>\n",
    "\n",
    "## 2. Example Kelloggs\n",
    "\n",
    "The aim here was, \n",
    "1. to replace the tiger on the Kellogg's packaging with a bee and \n",
    "2. to replace the tiger and the bowl of cornflakes\n",
    " \n",
    "and the cereal bowl.\n",
    "\n",
    "I created the inpaint image (mask_image) manually with a design program and uploaded it. \n",
    "\n",
    "The tests refer to different parameter values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e6fa280-f853-4ddc-8f92-3482bfcd7286",
   "metadata": {},
   "outputs": [],
   "source": [
    "# nur Tiger austauschen\n",
    "# strength = 0.7\n",
    "\n",
    "init_image = load_image('../5.0_pictures/kelloggs_resized.jpg').convert(\"RGB\")\n",
    "mask_image = load_image('../5.0_pictures/kellogsfrosties_inpaint.jpg').convert(\"RGB\")\n",
    "\n",
    "prompt = \"Honey Flavoured Cornflakes with a Bee\"\n",
    "image = pipe(\n",
    "    prompt=prompt, \n",
    "    image=init_image, \n",
    "    mask_image=mask_image, \n",
    "    num_inference_steps=50, \n",
    "    strength=0.70\n",
    ").images[0]\n",
    "\n",
    "# Bilder mit matplotlib darstellen\n",
    "fig, axes = plt.subplots(1, 3, figsize=(20, 8))\n",
    "\n",
    "# Ursprüngliches Bild anzeigen\n",
    "axes[0].imshow(init_image)\n",
    "axes[0].axis('off')\n",
    "axes[0].set_title('Original Image')\n",
    "\n",
    "# Inpaint Mask anzeigen\n",
    "axes[1].imshow(mask_image)\n",
    "axes[1].axis('off')\n",
    "axes[1].set_title('Inpaint Image')\n",
    "\n",
    "# #Generierte Bild anzeigen\n",
    "axes[2].imshow(image)\n",
    "axes[2].axis('off')\n",
    "axes[2].set_title(prompt)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c346ab05-3503-4005-83ef-5ff467a466ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# strength = 0.8, guidance scale = 10\n",
    "\n",
    "init_image = load_image('../5.0_pictures/kelloggs_resized.jpg').convert(\"RGB\")\n",
    "mask_image = load_image('../5.0_pictures/kellogsfrosties_inpaint_2.jpg').convert(\"RGB\")\n",
    "\n",
    "# prompt = \"Honey Flavoured Cornflakes with a Bee\"\n",
    "\n",
    "prompt = \"honey flavoured conflakes with a simple bee illustration, cereal box label design\"\n",
    "image = pipe(\n",
    "    prompt=prompt, \n",
    "    image=init_image, \n",
    "    mask_image=mask_image, \n",
    "    num_inference_steps=50, \n",
    "    strength=0.90, \n",
    "    guidance_scale=5\n",
    ").images[0]\n",
    "\n",
    "# Bilder mit matplotlib darstellen\n",
    "fig, axes = plt.subplots(1, 3, figsize=(20, 8))\n",
    "\n",
    "# Ursprüngliches Bild anzeigen\n",
    "axes[0].imshow(init_image)\n",
    "axes[0].axis('off')\n",
    "axes[0].set_title('Original Image')\n",
    "\n",
    "# Inpaint Mask anzeigen\n",
    "axes[1].imshow(mask_image)\n",
    "axes[1].axis('off')\n",
    "axes[1].set_title('Inpaint Image')\n",
    "\n",
    "# #Generierte Bild anzeigen\n",
    "axes[2].imshow(image)\n",
    "axes[2].axis('off')\n",
    "axes[2].set_title(prompt)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ce88d50-352d-4df2-b890-575daf52ac24",
   "metadata": {},
   "outputs": [],
   "source": [
    "init_image = load_image('../5.0_pictures/kellogsfrosties_removebg_preview.jpg').convert(\"RGB\")\n",
    "mask_image = load_image('../5.0_pictures/kellogsfrosties_inpaint_2.jpg').convert(\"RGB\")\n",
    "\n",
    "cluster/upload/5.0_pictures/kellogsfrosties_removebg_preview.jpg\n",
    "\n",
    "prompt = \"Honey Flavoured Cornflakes with a Bee\"\n",
    "image = pipe(\n",
    "    prompt=prompt, \n",
    "    image=init_image, \n",
    "    mask_image=mask_image, \n",
    "    num_inference_steps=50, \n",
    "    strength=0.80\n",
    ").images[0]\n",
    "\n",
    "image"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c801255d-1d96-43f4-ba9a-e63b29164587",
   "metadata": {},
   "source": [
    "<a id=\"ruf\"></a>\n",
    "## Example - RUF Backmischung\n",
    "\n",
    "The aim was to replace the apple cake with a chocolate cake. I got the pictures from the RUF website. Since the source image and the mask were in the format **544x800 px**, I also created the target image in the same dimensions.\n",
    "\n",
    "I tried to **change the apple pie to a chocolate cake** by testing out different parameter values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c710c16a-a2ad-40f0-980e-edafc4dc74d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# strength = 0.8\n",
    "\n",
    "init_image = load_image('../5.0_pictures/RUF_13726_Apfel-Haferflocken-Kuchen-1.png').convert(\"RGB\")\n",
    "mask_image = load_image('../5.0_pictures/RUF_13726-Apfel-Haferflocken-Kuchen-1_inpaint.jpg').convert(\"RGB\")\n",
    "\n",
    "prompt = \"Glossy Chocolate cake, delicous, highly detailed, dark chocolate\"\n",
    "image = pipe(\n",
    "    prompt=prompt, \n",
    "    image=init_image, \n",
    "    mask_image=mask_image, \n",
    "    height=800, \n",
    "    width=544,\n",
    "    num_inference_steps=50, \n",
    "    strength=0.80\n",
    ").images[0]\n",
    "\n",
    "# Bilder mit matplotlib darstellen\n",
    "fig, axes = plt.subplots(1, 3, figsize=(20, 8))\n",
    "\n",
    "# Ursprüngliches Bild anzeigen\n",
    "axes[0].imshow(init_image)\n",
    "axes[0].axis('off')\n",
    "axes[0].set_title('Original Image')\n",
    "\n",
    "# Inpaint Mask anzeigen\n",
    "axes[1].imshow(mask_image)\n",
    "axes[1].axis('off')\n",
    "axes[1].set_title('Inpaint Image')\n",
    "\n",
    "# #Generierte Bild anzeigen\n",
    "axes[2].imshow(image)\n",
    "axes[2].axis('off')\n",
    "axes[2].set_title(prompt)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec47af5e-0677-4c7b-a9b4-2da01e0138bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#cfg=7.0, strength=0.5\n",
    "\n",
    "init_image = load_image('../5.0_pictures/RUF_13726_Apfel-Haferflocken-Kuchen-1.png').convert(\"RGB\")\n",
    "mask_image = load_image('../5.0_pictures/RUF_13726-Apfel-Haferflocken-Kuchen-1_inpaint.jpg').convert(\"RGB\")\n",
    "\n",
    "prompt = \"Glossy Chocolate cake on a wooden table, delicous, highly detailed, professional food photography, realistic photo\"\n",
    "\n",
    "generator = torch.Generator().manual_seed(0)\n",
    "\n",
    "image = pipe(\n",
    "    prompt=prompt,\n",
    "    image=init_image,\n",
    "    mask_image=mask_image,\n",
    "    height=800, \n",
    "    width=544,\n",
    "    guidance_scale=7.0,\n",
    "    num_inference_steps=30,  # steps between 15 and 30 work well for us\n",
    "    strength=0.5,  # make sure to use `strength` below 1.0\n",
    "    generator=generator,\n",
    ").images[0]\n",
    "\n",
    "# Bilder mit matplotlib darstellen\n",
    "fig, axes = plt.subplots(1, 3, figsize=(20, 8))\n",
    "\n",
    "# Ursprüngliches Bild anzeigen\n",
    "axes[0].imshow(init_image)\n",
    "axes[0].axis('off')\n",
    "axes[0].set_title('Original Image')\n",
    "\n",
    "# Inpaint Mask anzeigen\n",
    "axes[1].imshow(mask_image)\n",
    "axes[1].axis('off')\n",
    "axes[1].set_title('Inpaint Image')\n",
    "\n",
    "# #Generierte Bild anzeigen\n",
    "axes[2].imshow(image)\n",
    "axes[2].axis('off')\n",
    "axes[2].set_title(prompt)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24d10c96-6cea-45fc-a59a-d89efdcb3c6e",
   "metadata": {},
   "source": [
    "compare results of high and low `strength`and `cfg` values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efb8ee56-ab31-4d83-ae3f-ac249f9a130a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#cfg=8.0, strength=0.8\n",
    "\n",
    "init_image = load_image('../5.0_pictures/RUF_13726_Apfel-Haferflocken-Kuchen-1.png').convert(\"RGB\")\n",
    "mask_image = load_image('../5.0_pictures/RUF_13726-Apfel-Haferflocken-Kuchen-1_inpaint.jpg').convert(\"RGB\")\n",
    "\n",
    "prompt = \"Glossy Chocolate cake, delicous, highly detailed, dark chocolate\"\n",
    "\n",
    "generator = torch.Generator().manual_seed(0)\n",
    "\n",
    "image1 = pipe(\n",
    "    prompt=prompt,\n",
    "    image=init_image,\n",
    "    mask_image=mask_image,\n",
    "    height=800, \n",
    "    width=544,\n",
    "    guidance_scale=8.0,\n",
    "    num_inference_steps=30,  # steps between 15 and 30 work well for us\n",
    "    strength=0.8,  # make sure to use `strength` below 1.0\n",
    "    generator=generator,\n",
    ").images[0]\n",
    "\n",
    "image2 = pipe(\n",
    "    prompt=prompt,\n",
    "    image=init_image,\n",
    "    mask_image=mask_image,\n",
    "    height=800, \n",
    "    width=544,\n",
    "    guidance_scale=1.0,\n",
    "    num_inference_steps=30,  # steps between 15 and 30 work well for us\n",
    "    strength=0.5,  # make sure to use `strength` below 1.0\n",
    "    generator=generator,\n",
    ").images[0]\n",
    "\n",
    "# Bilder mit matplotlib darstellen\n",
    "fig, axes = plt.subplots(1, 3, figsize=(20, 8))\n",
    "\n",
    "# Ursprüngliches Bild anzeigen\n",
    "axes[0].imshow(init_image)\n",
    "axes[0].axis('off')\n",
    "axes[0].set_title('Original Image')\n",
    "\n",
    "# Inpaint Mask anzeigen\n",
    "axes[1].imshow(image1)\n",
    "axes[1].axis('off')\n",
    "axes[1].set_title('cfg=8.0, strength=0.8')\n",
    "\n",
    "# #Generierte Bild anzeigen\n",
    "axes[2].imshow(image2)\n",
    "axes[2].axis('off')\n",
    "axes[2].set_title('cfg=1.0, strength=0.5')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23e0f8b9-dd6a-4f9d-bb89-48631a27475d",
   "metadata": {},
   "outputs": [],
   "source": [
    "init_image = load_image('../5.0_pictures/RUF_13726_Apfel-Haferflocken-Kuchen-1.png').convert(\"RGB\")\n",
    "mask_image = load_image('../5.0_pictures/RUF_13726-Apfel-Haferflocken-Kuchen-1_inpaint.jpg').convert(\"RGB\")\n",
    "\n",
    "prompt = \"Glossy Chocolate cake, brown cake, highly detailed food photography, chocolate chips around the cake\"\n",
    "negative_prompt=\"white cake\"\n",
    "\n",
    "generator = torch.Generator().manual_seed(0)\n",
    "\n",
    "image1 = pipe(\n",
    "    prompt=prompt,\n",
    "    negative_prompt=negative_prompt,\n",
    "    image=init_image,\n",
    "    mask_image=mask_image,\n",
    "    height=800, \n",
    "    width=544,\n",
    "    guidance_scale=10.0,\n",
    "    num_inference_steps=30,  # steps between 15 and 30 work well for us\n",
    "    strength=0.5,  # make sure to use `strength` below 1.0\n",
    "    generator=generator,\n",
    ").images[0]\n",
    "\n",
    "image1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62c668c3-5bde-447d-80f8-35a8e396ba72",
   "metadata": {},
   "source": [
    "<a id=\"keyfind1\"></a>\n",
    "\n",
    "## 4. Key Findings\n",
    "\n",
    "Inpainting is a **promising method** of specifically modifying images/packaging. \n",
    "\n",
    "While the entire image is revised during image-to-image generation, here you have the option of only revising the **desired sub-areas**. This is helpful as partial areas and elements such as the logo remain in the same place and in the same quality. \n",
    "<br>If the `strength` value is too low, the generated image is hardly changed. A value that is too high leads to very abstract results. The same applies to extreme `guidance_scale` values. A range of **0.3 - 0.7** has been found for `strength` and **5.0 - 10.0** for `guidance_scale` </br>\n",
    "<br>\n",
    "\n",
    "The tests of changing the apple pie to chocolate cake showed that it's working quite good (if you have found right parameter values + prompt). Here it was a `strength`value around 0.5 and a `prompt`that described some details like \"chocolate chips around the cake\" and a `negative_prompt` that the cake shouldn't be white.\n",
    "\n",
    "In addition, the manual way to create the inpainting mask is very inconvenient. An interface would be helpful here to mark the desired area directly. One possibility would be to create a local web gui via **Gradio**. </br>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
