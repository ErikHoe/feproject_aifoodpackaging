{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ad95f85f-2ae7-4f7f-af03-1e7ee7dd2ec2",
   "metadata": {},
   "source": [
    "# 02. Basic Image Generation + Functions\n",
    "\n",
    "## 04. Image-to-Image Generation\n",
    "\n",
    "### Content\n",
    "1. [Img2Img - Base Model](#base)\n",
    "2. [Img2Img - Comparison Base  + Refiner Model](#refiner)\n",
    "3. [Img2Img - Diffusion Process Grid](#grid1)\n",
    "4. [Img2Img - Examples Kelloggs (Honey Cornflakes)](#exampleskelloggs)\n",
    "5. [Img2Img - Examples Campusbier (Beer Can)](#examplescampusbier)\n",
    "6. [Key Findings](#keyfindings)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "962c1dd4-9e5e-4605-b679-b3f32f224478",
   "metadata": {},
   "source": [
    "## Description + Links\n",
    "\n",
    "* in addition to a text-prompt, you pass an initial image as a starting point for the diffusion process\n",
    "* the initial image is encoded to the latent space and noise is added to it\n",
    "* the denoising process **starts from the noisy initial image** (in the latent space), predicts the nose and removes the predicted noiseto get the new image\n",
    "\n",
    "**Parameters:**\n",
    "* **Strength (0-1)**: determines how much the generated image resembles the initial image\n",
    "    *  higher strength: value gives the model more creativity, a value of 1.0 means the initial image is more or less ignored\n",
    "    *  lower strength: generated image is more similar to the initial image\n",
    "* **Guidance Scale (default 5.0)**: used to control how closely aligned the generated image and text prompt are\n",
    "    * lower value: generated image is not that closely aligned to the prompt\n",
    "    * higher value: generated image is more aligned with the prompt\n",
    "---\n",
    "**Documentation**\n",
    "\n",
    "https://huggingface.co/docs/diffusers/using-diffusers/img2img\n",
    "\n",
    "https://huggingface.co/docs/diffusers/using-diffusers/sdxl"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "764ba302-4234-4d79-87bc-ebe32f491bab",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32b2414b-280c-4088-93a9-7c8ba66e400a",
   "metadata": {},
   "outputs": [],
   "source": [
    "%env HF_HOME=/cluster/user/ehoemmen/.cache\n",
    "%env HF_DATASETS_CACHE=/cluster/user/ehoemmen/.cache\n",
    "%env TRANSFORMERS_CACHE=/cluster/user/ehoemmen/.cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e534026-e215-426d-9e14-933a4445cd9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install -U diffusers invisible_watermark transformers accelerate safetensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e4c2bdf-4468-44f6-bf2f-cfbbae6bb5f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from diffusers import StableDiffusionXLImg2ImgPipeline, AutoPipelineForImage2Image\n",
    "from diffusers.utils import load_image, make_image_grid\n",
    "from PIL import Image\n",
    "\n",
    "base = StableDiffusionXLImg2ImgPipeline.from_pretrained(\n",
    "    \"stabilityai/stable-diffusion-xl-base-1.0\", torch_dtype=torch.float16, cache_dir=\"/cluster/user/ehoemmen/.cache\"\n",
    ")\n",
    "# pipe = pipe.to(\"cuda\")\n",
    "base.enable_model_cpu_offload()\n",
    "\n",
    "refiner = StableDiffusionXLImg2ImgPipeline.from_pretrained(\n",
    "    \"stabilityai/stable-diffusion-xl-refiner-1.0\", torch_dtype=torch.float16, cache_dir=\"/cluster/user/ehoemmen/.cache\"\n",
    ")\n",
    "# pipe = pipe.to(\"cuda\")\n",
    "refiner.enable_model_cpu_offload()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ad1bb8a-36b8-46c8-80bb-406a3520ceee",
   "metadata": {},
   "source": [
    "<a id=\"base\"></a>\n",
    "\n",
    "## 1. Img2Img - Base Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48dc93ff-be45-4ddd-8a8d-04273c4354fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load initial image\n",
    "url = \"https://huggingface.co/datasets/patrickvonplaten/images/resolve/main/aa_xl/000000009.png\"\n",
    "init_image = load_image(url).convert(\"RGB\")\n",
    "\n",
    "prompt = \"cowboy riding a horse\"\n",
    "\n",
    "# pass prompt and image to the pipeline\n",
    "image = base(prompt=prompt, \n",
    "             strenght=1.0,\n",
    "             guidance_scale=10,\n",
    "             num_inference_steps=50,\n",
    "             image=init_image\n",
    "            ).images[0]\n",
    "\n",
    "# make grid\n",
    "make_image_grid([init_image, image], rows=1, cols=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9c8df08-002a-4673-a027-41235f385a3f",
   "metadata": {},
   "source": [
    "<a id=\"refiner\"></a>\n",
    "\n",
    "## 2. Img2Img - Comparison Base and Refiner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff7e2750-a220-4fd0-b219-6624459de941",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare image\n",
    "url = \"https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/diffusers/img2img-sdxl-init.png\"\n",
    "init_image = load_image(url)\n",
    "\n",
    "# parameters (50 default inference steps - strength=0.7 --> 50 x 0.7 = 35 steps)\n",
    "prompt = \"Astronaut in a jungle, trees in the background, comic style, cold color palette, muted colors, detailed\"\n",
    "strength = 0.7\n",
    "cfg = 7.0\n",
    "\n",
    "# compare base and refiner pipeline\n",
    "base_image= base(prompt=prompt, \n",
    "                 image=init_image,\n",
    "                 guidance_scale=cfg,\n",
    "                 strength=strength\n",
    "                ).images[0]\n",
    "\n",
    "refiner_image = refiner(prompt=prompt, \n",
    "                        image=init_image,\n",
    "                        guidance_scale=cfg,\n",
    "                        strength=strength\n",
    "                       ).images[0]\n",
    "\n",
    "# create grid\n",
    "make_image_grid([init_image, base_image, refiner_image], rows=1, cols=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a7766c1-2da9-4c95-b14b-bd8f7e00ec6a",
   "metadata": {},
   "source": [
    "<a id=\"grid1\"></a>\n",
    "\n",
    "## 3. Img2Img - Diffusion Process Grid\n",
    "\n",
    "Here you can see that the diffusion process starts with the initial image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42eca41d-f45a-4663-b2e4-c75878cee0ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grid with 5 Process Steps\n",
    "\n",
    "n_images = 5\n",
    "prompt = \"Beer Can, delicous organic beer can, sustainable local brand, green label, with the text CAMPUSBIER\"\n",
    "url = '../5.0_pictures/campusbier_2.png'\n",
    "init_image = load_image(url)\n",
    "\n",
    "# Create a list of denoising_end values\n",
    "end = 1.0 / n_images\n",
    "denoising_ends = [end * (step + 1) for step in range(n_images)]\n",
    "\n",
    "# Seed setzen\n",
    "generator = torch.Generator(device=\"cuda\").manual_seed(2147483647) \n",
    "\n",
    "# Initialize images list\n",
    "images = []\n",
    "\n",
    "# Generate images for each denoising_end value\n",
    "for i in range(n_images):\n",
    "    generator.manual_seed(2147483647)\n",
    "    image = base(prompt=prompt, \n",
    "                     generator=generator,\n",
    "                     image=init_image,\n",
    "                     num_inference_steps=30, \n",
    "                     strength=0.7, \n",
    "                     guidance_scale=6.0,\n",
    "                     denoising_end=denoising_ends[i]\n",
    "                    ).images[0]\n",
    "    images.append(image)\n",
    "\n",
    "make_image_grid(images, rows=1, cols=n_images)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f87b22d9-443e-455c-ad76-f12fdde662d3",
   "metadata": {},
   "source": [
    "<a id=\"exampleskelloggs\"></a>\n",
    "\n",
    "## 4. Img2Img - Examples Kelloggs (Honey Cornflakes)\n",
    "\n",
    "**Comparing Base + Refiner** with differnent `stength` and `cfg` values."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58e65ad5-f7c2-4fb9-9928-63e0b1001145",
   "metadata": {},
   "source": [
    "High `stength`--> the initial image is mostly ignored."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6508ed94-bf08-4155-bcfe-581018fdf6b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare image\n",
    "url = '../5.0_pictures/kelloggs_resized.jpg'\n",
    "init_image = load_image(url)\n",
    "\n",
    "# parameters\n",
    "prompt = \"Honey Flavoured Cornflakes, Yellow Packaging design, cute bees, food photography, mockup\"\n",
    "strength = 0.8\n",
    "cfg = 7.0\n",
    "\n",
    "# pass prompt and image to base and refiner pipeline\n",
    "base_image = base(prompt=prompt, \n",
    "                 image=init_image, \n",
    "                 strength=strength, \n",
    "                 guidance_scale=cfg\n",
    "                ).images[0]\n",
    "\n",
    "refiner_image = base(prompt=prompt, \n",
    "                 image=init_image, \n",
    "                 strength=strength, \n",
    "                 guidance_scale=cfg\n",
    "                ).images[0]\n",
    "\n",
    "make_image_grid([init_image, base_image, refiner_image], rows=1, cols=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e900046-62d7-4333-9669-6366ae00d4ab",
   "metadata": {},
   "source": [
    "Low `strength` --> the initial image has higher influence\n",
    "\n",
    "Low `cfg` --> more creativity (model is not so focused on the prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3659335-4cdd-469c-a5cd-332f18bf7bd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare image\n",
    "url = '../5.0_pictures/kelloggs_resized.jpg'\n",
    "init_image = load_image(url)\n",
    "\n",
    "# parameters\n",
    "prompt = \"Honey Flavoured Cornflakes, Yellow Packaging design, cute bees, food photography, mockup\"\n",
    "strength = 0.4\n",
    "cfg = 4.0\n",
    "\n",
    "# pass prompt and image to base and refiner pipeline\n",
    "base_image = base(prompt=prompt, \n",
    "                 image=init_image, \n",
    "                 strength=strength, \n",
    "                 guidance_scale=cfg\n",
    "                ).images[0]\n",
    "\n",
    "refiner_image = base(prompt=prompt, \n",
    "                 image=init_image, \n",
    "                 strength=strength, \n",
    "                 guidance_scale=cfg\n",
    "                ).images[0]\n",
    "\n",
    "make_image_grid([init_image, base_image, refiner_image], rows=1, cols=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78178f95-5794-406d-bd10-76dd3bdfe829",
   "metadata": {},
   "source": [
    "High `strength`  +\n",
    "\n",
    "High `cfg`\n",
    "\n",
    "--> should be a really creative output, but sticking to the prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af41f4cf-b615-4c23-b96a-ece64f0885a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare image\n",
    "url = '../5.0_pictures/kelloggs_resized.jpg'\n",
    "init_image = load_image(url)\n",
    "\n",
    "# parameters\n",
    "prompt = \"Honey Flavoured Cornflakes, Yellow Packaging design, cute bees, food photography, professional mockup\"\n",
    "strength = 0.8\n",
    "cfg = 10.0\n",
    "\n",
    "# pass prompt and image to base and refiner pipeline\n",
    "refiner_image = refiner(prompt=prompt, \n",
    "                 image=init_image, \n",
    "                 strength=strength, \n",
    "                 guidance_scale=cfg\n",
    "                ).images[0]\n",
    "\n",
    "make_image_grid([init_image, refiner_image], rows=1, cols=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4163a554-5daa-45c0-bf22-e6f6e0af5be9",
   "metadata": {},
   "source": [
    "Low `strength` +\n",
    "\n",
    "Low `cfg`\n",
    "\n",
    "--> output should be similar to initial image, but creative as it's not so focused on the prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd8bdaf1-67d3-4a2e-9cf3-b031e309fae2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#strenght = 0.4, guidance scale = 4.0\n",
    "\n",
    "prompt = \"Honey Flavoured Cornflakes, Yellow Packaging design, cute bees, food photography\"\n",
    "strength = 0.4\n",
    "cfg = 4.0\n",
    "\n",
    "# pass prompt and image to pipeline\n",
    "image = refiner(prompt, \n",
    "                 image=init_image, \n",
    "                 strength=0.4, \n",
    "                 guidance_scale=4\n",
    "                ).images[0]\n",
    "\n",
    "make_image_grid([init_image, image], rows=1, cols=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "481c5f3b-5766-453e-8e20-14174f7f6204",
   "metadata": {},
   "source": [
    "<a id=\"examplescampusbier\"></a>\n",
    "\n",
    "## 5. Img2Img - Examples Campusbier "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8531e5a1-6be8-43b9-a361-1f1fa55e001a",
   "metadata": {},
   "source": [
    "General Test with the Campusbier, how it can influence the bottle and label (the building should be replaced with students)\n",
    "\n",
    "low `strength` +\n",
    "\n",
    "low `cfg`\n",
    "\n",
    "so the initial image has high influence on the image generation process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65e70c03-200a-4fd3-8e53-186a6368eca3",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = '../5.0_pictures/campusbier_2.png'\n",
    "init_image = load_image(url)\n",
    "\n",
    "prompt = \"Beer Bottle, students on the label, delicous beer, green colors, food photography, mockup\"\n",
    "negativ_prompt = \"can\"\n",
    "\n",
    "strength = 0.4\n",
    "cfg = 6.0\n",
    "\n",
    "# pass prompt and image to pipeline\n",
    "image = refiner(prompt, \n",
    "                negativ_prompt=negativ_prompt,\n",
    "                image=init_image, \n",
    "                strength=strength, \n",
    "                guidance_scale=cfg\n",
    "                ).images[0]\n",
    "\n",
    "make_image_grid([init_image, image], rows=1, cols=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f92fe39d-aff8-4e09-919d-3b3883516213",
   "metadata": {},
   "source": [
    "Creating a Campusbier **Beer Can**\n",
    "\n",
    "high `strength` +\n",
    "\n",
    "highter `cfg`\n",
    "\n",
    "should give the model the freedom and creativity to transform the bootle into a can"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a53fccc-fbdc-479d-b902-2673ebc5d799",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Campusbier Can\n",
    "#strenght = 0.7, guidance scale = 6.0\n",
    "\n",
    "url = '../5.0_pictures/campusbier_2.png'\n",
    "init_image = load_image(url)\n",
    "\n",
    "prompt = \"Beer Can, delicous organic beer can, sustainable local brand, green label, with the text CAMPUSBIER\"\n",
    "negativ_prompt = \"bottle\"\n",
    "\n",
    "# pass prompt and image to pipeline\n",
    "image = refiner(prompt=prompt, \n",
    "                 negativ_prompt=negativ_prompt,\n",
    "                 image=init_image, \n",
    "                 strength=0.9, \n",
    "                 guidance_scale=10.0\n",
    "                ).images[0]\n",
    "\n",
    "make_image_grid([init_image, image], rows=1, cols=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcdd51c3-8e56-488d-9ad4-a4c6821a0019",
   "metadata": {},
   "source": [
    "<a id=\"keyfindings\"></a>\n",
    "\n",
    "## Key Findings\n",
    "\n",
    "You have the option of using the two parameters **`Strength`** and **`Guidance Scale`** to either stay very close to the original image or to leave it almost unconsidered. This differs depending on the **application**, so that no recommendations for specific values can be made here.\n",
    "\n",
    "Depending on the application, the base or refiner model is more suitable. If the original image is to be modified to a greater extent, the **Base Model** is the better choice. If the initial image is to be optimized (focus on details such as eyes), the **Refiner Model** may be the better choice.\n",
    "\n",
    "It is important to use high-quality source images, as this forms the basis. For the packaging development application, it is helpful to keep both parameters low so as not to give the model too much freedom and to stay close to the original. \n",
    "<br>In general, however, the image-to-image pipeline is **not suitable for packaging development**. At high parameter values, the generated images are too far away from the original image (Kelloggs folding carton packaging was partially changed into completely new packaging such as cans or cups). At low parameter values, the model is usually not able to change the individual image elements sufficiently (the Kelloggs tiger remains a tiger and could not be changed into a bee). </br>\n",
    "\n",
    "But it worked to change the **Campusbier** glass bottle into a **beer can** (high parameter values for more freedom + negative prompt). This would at least give a first, rough impression of what the product could look like (some elements such as the color scheme would be adopted).\n",
    "\n",
    "Possibly suitable as a **creativity method** or in **combination with other image control features**. This was not tested as part of the project."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
