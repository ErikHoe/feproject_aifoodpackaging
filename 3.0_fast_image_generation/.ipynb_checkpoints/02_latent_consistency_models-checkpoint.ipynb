{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ebd00603-e4fa-4a04-934a-262398fa1c86",
   "metadata": {},
   "source": [
    "# 03. Fast Image Generation\n",
    "\n",
    "## 02. Latent Consistency Models (LCM)\n",
    "#### Content\n",
    "\n",
    "1. [Basic LCM Pipeline](#lcm)\n",
    "2. [Key-Findings](#keyfindings)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0d43f83-8d9c-427f-9160-47d09824fdb5",
   "metadata": {},
   "source": [
    "## Description + Links\n",
    "\n",
    "For latent consistency distillation, each model needs to be distilled separately. The core idea with LCM LoRA is to train just a small number of adapters, known as LoRA layers, instead of the full model. The resulting LoRAs can then be applied to any fine-tuned version of the model without having to distil them separately. \n",
    "\n",
    "---\n",
    "**Documentation**\n",
    "\n",
    "https://huggingface.co/docs/diffusers/api/pipelines/latent_consistency_models\n",
    "\n",
    "https://huggingface.co/blog/lcm_lora\n",
    "\n",
    "**Paper**\n",
    "\n",
    "[Luo, S., et al. (2023): Latent Consistency Models: Synthesizing High-Resolution Images with Few-Step Inference](https://arxiv.org/abs/2310.04378)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc4670e3-fcff-4f4e-bd12-b53373a03e46",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "025e5547-800d-4771-ba6a-2ffb058d5750",
   "metadata": {},
   "outputs": [],
   "source": [
    "%env HF_HOME=/cluster/user/ehoemmen/.cache\n",
    "%env HF_DATASETS_CACHE=/cluster/user/ehoemmen/.cache\n",
    "%env TRANSFORMERS_CACHE=/cluster/user/ehoemmen/.cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0640b4e9-f230-4c9e-b827-6e3fbc4f6671",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install -U invisible_watermark transformers accelerate safetensors peft diffusers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3f97c4d-4c8d-4135-abb9-ab697fa2d8a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from diffusers import DiffusionPipeline, LCMScheduler\n",
    "import torch\n",
    "\n",
    "# image grid\n",
    "from PIL import Image\n",
    "\n",
    "#Image Grid\n",
    "def image_grid(imgs, rows, cols):\n",
    "    assert len(imgs) == rows*cols\n",
    "\n",
    "    w, h = imgs[0].size\n",
    "    grid = Image.new('RGB', size=(cols*w, rows*h))\n",
    "    grid_w, grid_h = grid.size\n",
    "    \n",
    "    for i, img in enumerate(imgs):\n",
    "        grid.paste(img, box=(i%cols*w, i//cols*h))\n",
    "    return grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e2c686f-c3e5-4d8a-9735-1b1e975f30c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_id = \"stabilityai/stable-diffusion-xl-base-1.0\"\n",
    "lcm_lora_id = \"latent-consistency/lcm-lora-sdxl\"\n",
    "\n",
    "pipe = DiffusionPipeline.from_pretrained(model_id, variant=\"fp16\",cache_dir=\"/cluster/user/ehoemmen/.cache\")\n",
    "\n",
    "pipe.load_lora_weights(lcm_lora_id)\n",
    "pipe.scheduler = LCMScheduler.from_config(pipe.scheduler.config)\n",
    "# pipe.to(device=\"cuda\", dtype=torch.float16)\n",
    "pipe.enable_sequential_cpu_offload()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afa16959-ba14-4cd3-b6b2-eb93dbfbb1d6",
   "metadata": {},
   "source": [
    "<a id=\"lcm\"></a>\n",
    "\n",
    "## 1. Basic LCM Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7768da99-28a6-48b3-8062-cab91e31558c",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"close-up photography of old man standing in the rain at night, in a street lit by lamps, leica 35mm summilux\"\n",
    "images = pipe(\n",
    "    prompt=prompt,\n",
    "    num_inference_steps=4,\n",
    "    guidance_scale=1,\n",
    ").images[0]\n",
    "\n",
    "images"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bca7a2d7-5ab3-4be6-a6a9-d6e0c868b940",
   "metadata": {},
   "source": [
    "#### Diffusion Process Grid (1 - 8 steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "293d9784-1079-46ed-ab91-57f251788467",
   "metadata": {},
   "outputs": [],
   "source": [
    "images = []\n",
    "for steps in range(8):\n",
    "    generator = torch.Generator().manual_seed(1337)\n",
    "    image = pipe(\n",
    "        prompt=prompt,\n",
    "        num_inference_steps=steps+1,\n",
    "        guidance_scale=1,\n",
    "        generator=generator,\n",
    "    ).images[0]\n",
    "    images.append(image)\n",
    "\n",
    "grid = image_grid(images, rows=2, cols=4)\n",
    "\n",
    "grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5300a0e2-46a4-4ae3-803f-9dd927ad4bdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"cereal package, bees on the package, honey flavoured, food mockup\"\n",
    "images = pipe(\n",
    "    prompt=prompt,\n",
    "    num_inference_steps=4,\n",
    "    guidance_scale=1,\n",
    ").images[0]\n",
    "\n",
    "images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae4098ea-2693-4fa4-a53c-1cde37aad839",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"Croissant  on a wodden table, awesome food photography, studio lightning, warm colors and sunlight in background\"\n",
    "images = pipe(\n",
    "    prompt=prompt,\n",
    "    num_inference_steps=4,\n",
    "    guidance_scale=1,\n",
    ").images[0]\n",
    "\n",
    "images"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a0f5d43-7276-43c6-a8fb-673df2c629b7",
   "metadata": {},
   "source": [
    "<a id=\"keyfindings\"></a>\n",
    "\n",
    "## Key Findings\n",
    "\n",
    "The general image quality is very good, sometimes with only one step. As soon as it came to packaging and more specific requirements were made in the prompt, it became imprecise and the quality deteriorated (e. g.cornflakes packaging was difficult). \n",
    "\n",
    "However, good results are achieved, especially with photorealistic images."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
